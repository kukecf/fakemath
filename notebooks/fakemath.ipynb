{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 0. Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from alive_progress import alive_bar\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, MaxPooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "EXAMPLE_PATH = os.path.join('data', 'handwritten_ex')\n",
    "DATA_PATH = os.path.join('data', 'dataset', 'CompleteImages','All data (Compressed)')\n",
    "TEST_DATA_PATH = os.path.join('data', 'test')\n",
    "TRAIN_DATA_PATH = os.path.join('data', 'train')\n",
    "MODELS_PATH = os.path.join('models','digit_cl')\n",
    "INPUT_IMAGE_SIZE = (28,28)\n",
    "N_CLASSES = 16\n",
    "\n",
    "labels = ['%', '+', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '[', ']', '_']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 0.3 Set memory growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Implement a handwritten character detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.1 Handling bounding box intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Jaccard index (IoU) of bounding boxes A and B\n",
    "def bb_iou(boxA, boxB):\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2]+boxA[0], boxB[2]+boxB[0])\n",
    "    yB = min(boxA[3]+boxA[1], boxB[3]+boxB[1])\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    return iou\n",
    "\n",
    "\n",
    "def bb_area(bb):\n",
    "    _, _, w, h = bb\n",
    "    return w * h\n",
    "\n",
    "\n",
    "def detect_postprocess_bb(bounding_boxes):\n",
    "    indices_rem = []\n",
    "    for i in range(len(bounding_boxes) - 1):\n",
    "        for j in range(i + 1, len(bounding_boxes)):\n",
    "            iou = bb_iou(bounding_boxes[i], bounding_boxes[j])\n",
    "            if iou > 0:\n",
    "                areaI = bb_area(bounding_boxes[i])\n",
    "                areaJ = bb_area(bounding_boxes[j])\n",
    "                if areaI > areaJ:\n",
    "                    indices_rem.append(j)\n",
    "                else:\n",
    "                    indices_rem.append(i)\n",
    "    bounding_boxes = [i for j, i in enumerate(bounding_boxes) if j not in indices_rem]\n",
    "    return bounding_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.2 Build detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_characters(image_path, kernel=(5, 5), show_results=False):\n",
    "    img = cv.imread(image_path)\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    ret, binary = cv.threshold(gray, 127, 255, cv.THRESH_BINARY)\n",
    "    opening = cv.morphologyEx(binary, cv.MORPH_CLOSE, kernel)\n",
    "    contours, _ = cv.findContours(opening, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "    bounding_boxes = []\n",
    "    for contour in contours:\n",
    "        area = cv.contourArea(contour)\n",
    "        if area > 200 and area < 5000:\n",
    "            x, y, w, h = cv.boundingRect(contour)\n",
    "            bounding_boxes.append((x, y, w, h))\n",
    "    bounding_boxes = detect_postprocess_bb(bounding_boxes)\n",
    "    if show_results:\n",
    "        for (x, y, w, h) in bounding_boxes:\n",
    "            cv.rectangle(img, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "            #cv.putText(img, f'({x},{y})', (x - 5, y - 5), cv.FONT_HERSHEY_SIMPLEX, 1.0, (200, 15, 0), 1)\n",
    "        cv.imshow('Image', img)\n",
    "        cv.imshow('Opening', opening)\n",
    "        cv.waitKey(0)\n",
    "\n",
    "    return sorted(bounding_boxes,key = lambda x: x[0]) # sorted by x value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(EXAMPLE_PATH)\n",
    "it_files = iter(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#Try it out...\n",
    "\n",
    "file = next(it_files)\n",
    "detect_characters(os.path.join(EXAMPLE_PATH, file), show_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implement a handwritten character classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Let's scale all bounding boxes to the same size!\n",
    "# First, we need to assess how wide and how high should the bounding boxes be.\n",
    "bb = []\n",
    "for file in files:\n",
    "    bb.extend(detect_characters(os.path.join(EXAMPLE_PATH, file)))\n",
    "\n",
    "wmin = min(bb,key=lambda x: x[2])[2]\n",
    "\n",
    "hmin = min(bb,key=lambda x: x[3])[3]\n",
    "\n",
    "wmax = max(bb,key=lambda x: x[2])[2]\n",
    "hmax = max(bb,key=lambda x: x[3])[3]\n",
    "\n",
    "print((wmin,wmax),(hmin,hmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Preparing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def training_preprocess(image_path,label):\n",
    "    byte_image = tf.io.read_file(image_path)\n",
    "    img = tf.io.decode_jpeg(byte_image)\n",
    "    img = tf.image.resize(img, INPUT_IMAGE_SIZE)\n",
    "    return img, label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Get datasets...\n",
    "class_ds_size=20000\n",
    "for idx, label in enumerate(labels):\n",
    "    ds = tf.data.Dataset.list_files(os.path.join(DATA_PATH, label, \"*.png\")).take(class_ds_size)\n",
    "    labelling = tf.data.Dataset.from_tensor_slices(tf.ones(len(ds)) * idx, name='labels')\n",
    "    data = tf.data.Dataset.zip((ds, labelling))\n",
    "    data = data.map(training_preprocess)\n",
    "    data = data.shuffle(buffer_size=1024)\n",
    "    if idx == 0:\n",
    "        train_data = data.take(int(len(data) * .7))\n",
    "        test_data = data.skip(int(len(data) * .7))\n",
    "        test_data = test_data.take(int(len(data) * .3))\n",
    "    else:\n",
    "        train_data = train_data.concatenate(data.take(int(len(data) * .7)))\n",
    "        test = data.skip(int(len(data) * .7))\n",
    "        test_data = test_data.concatenate(test.take(int(len(data) * .3)))\n",
    "    train_data.cache()\n",
    "    test_data.cache()\n",
    "tf.data.experimental.save(train_data, TRAIN_DATA_PATH)\n",
    "tf.data.experimental.save(test_data, TEST_DATA_PATH)\n",
    "print(f'Train data length:{len(train_data)}, test data length: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.2 Image preprocessing and getting image slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# dataset : https://www.kaggle.com/michelheusser/handwritten-digits-and-operators\n",
    "def preprocess_img(image):\n",
    "    #image = np.array(tf.image.resize_with_pad(image, INPUT_IMAGE_SIZE[1],INPUT_IMAGE_SIZE[0]))\n",
    "    image = np.array(tf.image.resize(image, INPUT_IMAGE_SIZE))\n",
    "    img = image / 255.0  # normalization\n",
    "    return img\n",
    "\n",
    "def get_digit_images(image_path,kernel=(5, 5)):\n",
    "    digit_bbs = detect_characters(image_path,kernel=kernel)\n",
    "    images = []\n",
    "    img = cv.imread(image_path)\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    ret, binary = cv.threshold(img, 127, 255, cv.THRESH_BINARY)\n",
    "    for bb in digit_bbs:\n",
    "        (x,y,w,h)=bb\n",
    "        char_img = tf.convert_to_tensor(binary[y:y + h, x:x + w])\n",
    "        char_img = np.array(tf.reshape(char_img, [char_img.shape[0],char_img.shape[1],1]))\n",
    "        images.append(preprocess_img(char_img))\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Try it out...\n",
    "\n",
    "file = next(it_files)\n",
    "images = get_digit_images(os.path.join(EXAMPLE_PATH, file))\n",
    "for i, img in enumerate(images):\n",
    "    cv.imshow(f'Image {i}',img)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.3 Define the model (and its variant in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_digit_classifier():\n",
    "    in_size = INPUT_IMAGE_SIZE\n",
    "    input = Input(shape=(in_size[0], in_size[1], 1), name='input')\n",
    "    conv_1 = Conv2D(64, (5, 5), activation='relu')(input)\n",
    "    max_1 = MaxPooling2D(64, (2, 2), padding='same')(conv_1)\n",
    "\n",
    "    conv_2 = Conv2D(32, (6, 6), activation='relu')(max_1)\n",
    "    max_2 = MaxPooling2D(32, (2, 2), padding='same')(conv_2)\n",
    "\n",
    "    conv_3 = Conv2D(16, (4, 4), activation='relu')(max_2)\n",
    "    max_3 = MaxPooling2D(16, (2, 2), padding='same')(conv_3)\n",
    "\n",
    "    flat_1 = Flatten()(max_3)\n",
    "    dense_1 = Dense(16, activation='softmax')(flat_1)\n",
    "\n",
    "    return Model(inputs=[input], outputs=[dense_1], name='digit_classifier')\n",
    "\n",
    "def create_deeper_digit_classifier():\n",
    "    in_size = INPUT_IMAGE_SIZE\n",
    "    input = Input(shape=(in_size[0], in_size[1], 1), name='input')\n",
    "\n",
    "    conv_1 = Conv2D(64, (4, 4), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(\n",
    "        input)\n",
    "    max_1 = MaxPooling2D(64, (2, 2), padding='same')(conv_1)\n",
    "\n",
    "    b_norm_1 = BatchNormalization(momentum=0.8)(max_1)\n",
    "\n",
    "    conv_2 = Conv2D(64, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-5))(b_norm_1)\n",
    "    max_2 = MaxPooling2D(32, (2, 2), padding='same')(conv_2)\n",
    "    do_1 = Dropout(0.12)(max_2)\n",
    "\n",
    "    conv_3 = Conv2D(128, (4, 4), activation='relu', padding='same', bias_regularizer=tf.keras.regularizers.l2(5e-5),\n",
    "                    kernel_regularizer=tf.keras.regularizers.l2(1e-5))(do_1)\n",
    "    max_3 = MaxPooling2D(32, (2, 2), padding='same')(conv_3)\n",
    "    do_2 = Dropout(0.2)(max_3)\n",
    "\n",
    "    conv_4 = Conv2D(128, (2, 2), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-5))(do_2)\n",
    "    max_4 = MaxPooling2D(32, (2, 2), padding='same')(conv_4)\n",
    "    do_3 = Dropout(0.2)(max_4)\n",
    "\n",
    "    flat = Flatten()(do_3)\n",
    "    dense_1 = Dense(512, activation='relu',\n",
    "                    bias_regularizer=tf.keras.regularizers.l2(1e-4),\n",
    "                    activity_regularizer=tf.keras.regularizers.l2(1e-5))(flat)\n",
    "\n",
    "    dense_2 = Dense(128, activation='relu',\n",
    "                    bias_regularizer=tf.keras.regularizers.l2(1e-5))(dense_1)\n",
    "    b_norm_2 = BatchNormalization(momentum=0.8)(dense_2)\n",
    "\n",
    "    dense_3 = Dense(64, activation='relu',\n",
    "                    bias_regularizer=tf.keras.regularizers.l2(1e-5))(b_norm_2)\n",
    "    do_4 = Dropout(0.2)(dense_3)\n",
    "\n",
    "    dense_4 = Dense(N_CLASSES, activation='softmax',\n",
    "                    bias_regularizer=tf.keras.regularizers.l2(1e-5),\n",
    "                    activity_regularizer=tf.keras.regularizers.l2(1e-5))(do_4)\n",
    "\n",
    "    return Model(inputs=[input], outputs=[dense_4], name='digit_classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.4 Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, batch, loss, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        X = batch[0]\n",
    "        y_true = batch[1]\n",
    "        y_pred = model(X, training=True)\n",
    "        loss_v = loss(y_true, y_pred)\n",
    "        grad = tape.gradient(loss_v, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grad, model.trainable_variables))\n",
    "        return loss_v\n",
    "\n",
    "def train(data, epochs, lr = 5e-5):\n",
    "    data = data.batch(100)\n",
    "    data = data.prefetch(20)  # to prevent bottlenecking\n",
    "    model = create_digit_classifier()\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    optimizer = tf.keras.optimizers.Adam(lr)\n",
    "    checkpoint_dir = \"./checkpoints\"\n",
    "    checkpoint_prefix = os.path.join(checkpoint_dir, 'chkpt')\n",
    "    checkpoint = tf.train.Checkpoint(opt=optimizer, model=model)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"Epoch {epoch}/{epochs}\")\n",
    "        with alive_bar(len(data)) as bar:\n",
    "            for batch in data:\n",
    "                train_step(model, batch, loss, optimizer)\n",
    "                bar()\n",
    "            if epoch % 10 == 0:\n",
    "                checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "    model.save(os.path.join(MODELS_PATH, 'digit_classifier.h5'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test(model, data):\n",
    "    data = data.batch(16)\n",
    "    data = data.prefetch(8)\n",
    "    recall = Recall()\n",
    "    precision = Precision()\n",
    "    for idx, batch in enumerate(data):\n",
    "        X = batch[:2]\n",
    "        y_true = batch[2]\n",
    "        y_out = model.predict(X)\n",
    "        y_pred = [1 if pred > 0.5 else 0 for pred in y_out]\n",
    "        recall.update_state(y_true, y_pred)\n",
    "        precision.update_state(y_true, y_pred)\n",
    "        print(f'Batch {idx}')\n",
    "        print(f'True: {y_true}\\nPred: {y_pred}')\n",
    "        print(f'Precision: {precision.result().numpy()}, recall: {recall.result().numpy()}\\n')\n",
    "\n",
    "def load_latest_model():\n",
    "    return tf.keras.models.load_model(os.path.join(MODELS_PATH, 'digit_classifier.h5'))\n",
    "\n",
    "def load_best_model():\n",
    "    return tf.keras.models.load_model(os.path.join(MODELS_PATH, 'digit_classifier_best.h5'))\n",
    "\n",
    "def get_expression(model, image_path, kernel=(5, 5)):\n",
    "    digit_images = get_digit_images(image_path, kernel)\n",
    "    y_out = model.predict(digit_images)\n",
    "    y_pred = tf.math.argmax(y_out, axis=1)\n",
    "    expression = \"\"\n",
    "    for y in y_pred:\n",
    "        expression += labels[y]\n",
    "    return expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implement a solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def op(digit1, operator, digit2):\n",
    "    digit1, digit2 = float(digit1), float(digit2)\n",
    "    if operator == '_':\n",
    "        res = digit1 * digit2\n",
    "    elif operator == '%':\n",
    "        res = digit1 / digit2\n",
    "    elif operator == '+':\n",
    "        res = digit1 + digit2\n",
    "    elif operator == '-':\n",
    "        res = digit1 - digit2\n",
    "    return res\n",
    "\n",
    "\n",
    "def is_operator(char):\n",
    "    return char == '+' or char == '-' or char == '%' or char == '_'\n",
    "\n",
    "\n",
    "def is_float(slice):\n",
    "    if is_operator(slice[0]):\n",
    "        return False\n",
    "    try:\n",
    "        float(slice)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "def numbers_op(exp: str, op: str):\n",
    "    op_ind = exp.find(op)\n",
    "    start_ind = -1\n",
    "    end_ind = -1\n",
    "    for ind in range(1, op_ind + 1):\n",
    "        i = op_ind - ind\n",
    "        slice = exp[i:op_ind]\n",
    "        if is_float(slice):\n",
    "            start_ind = i\n",
    "        else:\n",
    "            break\n",
    "    for i in range(op_ind + 1, len(exp)):\n",
    "        slice = exp[op_ind + 1:i + 1]\n",
    "        if is_float(slice):\n",
    "            end_ind = i\n",
    "        else:\n",
    "            break\n",
    "    return exp[:start_ind], exp[start_ind:end_ind + 1], exp[end_ind + 1:]\n",
    "\n",
    "\n",
    "def branch(exp, operator):\n",
    "    f, s, t = numbers_op(exp, operator)\n",
    "    res = my_solver(s)\n",
    "    if f != \"\":\n",
    "        first = my_solver(f[:-1])\n",
    "        res = op(first, f[-1], res)\n",
    "    if t != \"\":\n",
    "        third = my_solver(t[1:])\n",
    "        res = op(res, t[0], third)\n",
    "    return res\n",
    "\n",
    "\n",
    "def terminal(exp):\n",
    "    ops = ['+', '-', '%', '_']\n",
    "    brackets = ['[', ']']\n",
    "    count_ops = {op: exp.count(op) for op in ops}\n",
    "    count_br = {br: exp.count(br) for br in brackets}\n",
    "    if sum(count_ops.values()) == 1 and sum(count_br.values()) == 0:\n",
    "        for key in count_ops.keys():\n",
    "            if count_ops[key] == 1:\n",
    "                return key\n",
    "    return None\n",
    "\n",
    "\n",
    "def remove_brackets(exp):\n",
    "    closed_ind = exp.find(']')\n",
    "    open_ind = exp.rfind('[', 0, closed_ind)\n",
    "    while open_ind != -1 and closed_ind != -1:\n",
    "        bracket_exp = exp[open_ind + 1:closed_ind]\n",
    "        left_exp = exp[:open_ind]\n",
    "        right_exp = exp[closed_ind + 1:]\n",
    "        exp = left_exp + str(my_solver(bracket_exp)) + right_exp\n",
    "        open_ind, closed_ind = exp.rfind('['), exp.find(']')\n",
    "    return exp\n",
    "\n",
    "\n",
    "def my_solver(exp: str):\n",
    "    operator = terminal(exp)\n",
    "    if operator is not None:\n",
    "        [first, second] = exp.split(operator)\n",
    "        return op(first, operator, second)\n",
    "    mul_ind = exp.find('_')\n",
    "    div_ind = exp.find('%')\n",
    "    if mul_ind < div_ind and mul_ind != -1:\n",
    "        return branch(exp, '_')\n",
    "    if div_ind != -1:\n",
    "        return branch(exp, '%')\n",
    "    add_ind = exp.find('+')\n",
    "    sub_ind = exp.find('-')\n",
    "    if add_ind < sub_ind and add_ind != -1:\n",
    "        return branch(exp, '+')\n",
    "    if sub_ind != -1:\n",
    "        return branch(exp, '-')\n",
    "    if exp != \"\":\n",
    "        return int(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def uglify(exp):\n",
    "    new = exp.replace('/', '%')\n",
    "    new = new.replace('*', '_')\n",
    "    new = new.replace('(', '[')\n",
    "    new = new.replace(')', ']')\n",
    "    return new\n",
    "\n",
    "\n",
    "def pretty(exp):\n",
    "    new = exp.replace('%', '/')\n",
    "    new = new.replace('_', '*')\n",
    "    new = new.replace('[', '(')\n",
    "    new = new.replace(']', ')')\n",
    "    return new\n",
    "\n",
    "\n",
    "def evaluate_expression(exp):\n",
    "    return my_solver(remove_brackets(exp))\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def solve_and_draw(model, image_path, kernel=(5, 5)):\n",
    "    bbs = detect_characters(image_path, kernel=kernel)\n",
    "    limits = [(x, y, x + w, y + h) for (x, y, w, h) in bbs]\n",
    "    [_, _, x_max, y_max] = list(np.amax(limits, axis=0))\n",
    "    [x_min, y_min, _, _] = list(np.amin(limits, axis=0))\n",
    "    exp = get_expression(model, image_path, kernel=kernel)\n",
    "    img = cv.imread(image_path)\n",
    "    cv.rectangle(img, (x_min, y_min), (x_max, y_max), (0, 0, 255), 2)\n",
    "    cv.putText(img, str(pretty(exp)), (x_min - 5, y_min - 5), cv.FONT_HERSHEY_SIMPLEX, 1.0, (200, 15, 0), 1)\n",
    "    try:\n",
    "        cv.putText(img, str(evaluate_expression(exp)), (x_max + 5, y_min - 5), cv.FONT_HERSHEY_SIMPLEX, 1.0,\n",
    "                   (200, 15, 0), 1)\n",
    "    except ValueError:\n",
    "        print(\"Unable to evaluate expression\")\n",
    "    cv.imshow('Expression', img)\n",
    "    cv.waitKey(0)\n"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (fakemath)",
   "language": "python",
   "name": "pycharm-8c0b6694"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}